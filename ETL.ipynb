{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) ETL (b) Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PycharmProjects\\smart-travels\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import time\n",
    "from __future__ import print_function\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from googleapiclient.errors import HttpError\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "from gdrive.gdrive_handler import GspreadHandler\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import pandas as pd\n",
    "from settings import GEMINI_API_KEY\n",
    "from llm_handler.GHandler import GHandler\n",
    "import fitz  # Import PyMuPDF\n",
    "\n",
    "# Replace with your credentials file path\n",
    "CREDENTIALS_FILE = 'smart-platform.json'\n",
    "SHEET_NAME = \"Master Database\" \n",
    "WORKSHEET_NAME = \"inventory\"\n",
    "\n",
    "gspread_handler = GspreadHandler(credentials_filepath=CREDENTIALS_FILE)\n",
    "\n",
    "def gemini_ocr(file_path):\n",
    "    \"\"\"Performs OCR on the given PDF using Gemini and returns extracted text.\"\"\"\n",
    "    ghandler = GHandler(GEMINI_API_KEY, generation_config={\"temperature\": 0.9, \"top_p\": 0.95, \"top_k\": 40, \"max_output_tokens\": 40000}, block_threshold=\"BLOCK_NONE\")\n",
    "    prompt = \"You are an OCR bot. Extract ALL the text from the image as raw text. Ensure all pricing, phone numbers, and emails are extracted ACCURATELY. OCR text output is sometimes wrong, so correct it where needed.\"\n",
    "\n",
    "    doc = fitz.open(file_path)\n",
    "    extracted_text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))  # Increase resolution for better OCR\n",
    "        image_path = file_path.replace('.pdf', f'_page_{page_num + 1}.jpg')\n",
    "        pix.save(image_path)  # Save each page as an image\n",
    "        try:\n",
    "            response = ghandler.prompt_image(image_path=image_path, prompt_1=prompt, prompt_2=None, model_name=\"gemini-pro-vision\")\n",
    "            print(response)\n",
    "            extracted_text += response.text\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for {file_path} - skipping: {e}\")\n",
    "        os.remove(image_path)  # Clean up the image file\n",
    "\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "def extract_folder_id(url):\n",
    "    \"\"\"Extracts the folder ID from a Google Drive URL using regular expressions.\"\"\"\n",
    "\n",
    "    pattern = r\"folders/([A-Za-z0-9_-]+)\\?\"  # Pattern to match folder ID\n",
    "    match = re.search(pattern, url)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1)  # Return the captured folder ID\n",
    "    else:\n",
    "        return None  # No match found\n",
    "\n",
    "def update_google_sheet(destination, title, text):\n",
    "    \"\"\"Updates the Google Sheet with the extracted text.\"\"\"\n",
    "    data = [{\"Destination\": destination, \"Title\": title, \"Text\": text}]\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n",
    "    # replace with the correct sheet name \n",
    "    gspread_handler.update_cols(df, SHEET_NAME, WORKSHEET_NAME) #replace with the correct sheet name \n",
    "\n",
    "\n",
    "def get_google_drive_service():\n",
    "  \"\"\"Initializes the Google Drive API service.\"\"\"\n",
    "  scopes = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "  credentials = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_FILE, scopes)\n",
    "  service = build('drive', 'v3', credentials=credentials)\n",
    "  return service\n",
    "\n",
    "def download_file(service, file_id, file_name):\n",
    "    \"\"\"Downloads the specified file from Google Drive.\"\"\"\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    request = service.files().get_media(fileId=file_id)\n",
    "    fh = io.FileIO(file_name, 'wb')\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "    done = False\n",
    "    while done is False:\n",
    "        status, done = downloader.next_chunk()\n",
    "        print(f\"Download {int(status.progress() * 100)}%\")\n",
    "\n",
    "def get_folder_contents(service, folder_id):\n",
    "    \"\"\"Retrieves a list of PDF files within the specified folder and subfolders.\"\"\"\n",
    "    all_files = []\n",
    "    page_token = None\n",
    "    while True:\n",
    "        try:\n",
    "            results = service.files().list(\n",
    "                pageSize=1000,  # Fetch a larger batch for efficiency\n",
    "                fields=\"nextPageToken, files(id, name, mimeType)\",\n",
    "                q=f\"'{folder_id}' in parents and mimeType='application/pdf'\",  # Filter for PDFs\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "\n",
    "            all_files.extend(results.get('files', []))\n",
    "            page_token = results.get('nextPageToken')\n",
    "            if not page_token:\n",
    "                break  # No more pages\n",
    "\n",
    "        except HttpError as error:\n",
    "            print(f\"An error occurred: {error}\")\n",
    "            return None\n",
    "\n",
    "    return all_files\n",
    "\n",
    "\n",
    "def get_download_link(item):\n",
    "  \"\"\"Retrieves the download link for a file based on its mimeType.\"\"\"\n",
    "  if item['mimeType'].startswith('application/'):  # Check if it's a Google Doc\n",
    "    return None  # Google Docs don't have direct download links\n",
    "  else:\n",
    "    return f\"https://drive.google.com/uc?export=download&id={item['id']}\"\n",
    "\n",
    "\n",
    "def run_ETL(folder_link):\n",
    "    \"\"\"Main function to download, OCR, and update Google Sheets.\"\"\"\n",
    "    folder_id = extract_folder_id(folder_link)\n",
    "    service = get_google_drive_service()\n",
    "    folder_contents = get_folder_contents(service, folder_id)\n",
    "\n",
    "    if folder_contents:\n",
    "        print(f\"Found {len(folder_contents)} PDF files in the specified folder.\")\n",
    "        for item in folder_contents:\n",
    "            print(f\"Processing: {item['name']}\")\n",
    "            file_name = item['name']\n",
    "            file_id = item['id']\n",
    "            # file_path = os.path.join(\"downloaded_pdfs\", file_name)\n",
    "            file_path = file_name\n",
    "\n",
    "            print(f\"Downloading: {file_name}\")\n",
    "            download_file(service, file_id, file_path)\n",
    "            print(f\"Downloaded: {file_name}\")\n",
    "\n",
    "            # Extract destination and title from file name\n",
    "            parts = file_name.split('/')\n",
    "            destination = parts[-2] if len(parts) > 1 else \"\"\n",
    "            title = os.path.splitext(parts[-1])[0]\n",
    "\n",
    "            # Perform OCR\n",
    "            print(f\"Performing OCR on: {file_name}\")\n",
    "            text = gemini_ocr(file_path)\n",
    "            time.sleep(30)\n",
    "            # Update Google Sheet\n",
    "            print(f\"Updating Google Sheet with: {file_name}\")\n",
    "            update_google_sheet(destination, title, text)\n",
    "            \n",
    "            os.remove(file_path) # remove file after using\n",
    "    else:\n",
    "        print(\"No PDF files found in the specified folder.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 PDF files in the specified folder.\n",
      "Processing: partners - sabah - adventure water sports/riverbug asia the white water \n",
      "Downloading: partners - sabah - adventure water sports/riverbug asia the white water \n",
      "Download 100%\n",
      "Downloaded: partners - sabah - adventure water sports/riverbug asia the white water \n",
      "Performing OCR on: partners - sabah - adventure water sports/riverbug asia the white water \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image format  not in ('png', 'pnm', 'pgm', 'ppm', 'pbm', 'pam', 'psd', 'ps', 'jpg', 'jpeg')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6392\\2299713504.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# folder_link = \"https://drive.google.com/drive/folders/1jjLefPWa4xTp4WKwkx7CTKzj2b-hI8SN?usp=drive_link\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# https://drive.google.com/drive/folders/1ZmZg9Y-Irphr5hBeGNYPdaUdDYlPcUrX?usp=drive_link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# https://drive.google.com/drive/folders/1uD7SEGQ5Y2o6oXMp-s53kKnKXXsVSD-X?usp=drive_link -- this one not cos not png?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# https://drive.google.com/drive/folders/11h9zIUN9MU9m8MyEkIJzp-dAjjSNyyUp?usp=drive_link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mrun_ETL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Process flow:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# to_be_processed folder --> datapipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6392\\205150567.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(folder_link)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;31m# Perform OCR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mPerforming OCR on: \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgemini_ocr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;31m# Update Google Sheet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mUpdating Google Sheet with: \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6392\\205150567.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpage_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mpix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_pixmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfitz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Increase resolution for better OCR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.pdf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33mf'\u001b[0m\u001b[1;33m_page_\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mpage_num\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m.jpg\u001b[0m\u001b[1;33m'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mpix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Save each page as an image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mghandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompt_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gemini-pro-vision\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\PycharmProjects\\smart-travels\\.venv\\Lib\\site-packages\\pymupdf\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, filename, output, jpg_quality)\u001b[0m\n\u001b[0;32m  10266\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10268\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_formats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10270\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mImage format \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m not in \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_formats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10272\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'%s' cannot have alpha\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorspace\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Image format  not in ('png', 'pnm', 'pgm', 'ppm', 'pbm', 'pam', 'psd', 'ps', 'jpg', 'jpeg')"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace with the ID of the target folder\n",
    "folder_link = \"https://drive.google.com/drive/folders/1_F3dWedZ4v15HZZwlmWxWtUVMPT-rMki?usp=drive_link\"\n",
    "# folder_link = \"https://drive.google.com/drive/folders/1jjLefPWa4xTp4WKwkx7CTKzj2b-hI8SN?usp=drive_link\"\n",
    "# https://drive.google.com/drive/folders/1ZmZg9Y-Irphr5hBeGNYPdaUdDYlPcUrX?usp=drive_link\n",
    "# https://drive.google.com/drive/folders/1uD7SEGQ5Y2o6oXMp-s53kKnKXXsVSD-X?usp=drive_link -- this one not cos not png?\n",
    "# https://drive.google.com/drive/folders/11h9zIUN9MU9m8MyEkIJzp-dAjjSNyyUp?usp=drive_link\n",
    "run_ETL(folder_link)\n",
    "\n",
    "# Process flow:\n",
    "# to_be_processed folder --> datapipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# Replace with your credentials file path\n",
    "CREDENTIALS_FILE = 'smart-platform.json'\n",
    "\n",
    "# Replace with the ID of the target folder\n",
    "FOLDER_ID = '1nstotWI9LYvUamNw-NSew-jnVDD7VAaH'\n",
    "\n",
    "\n",
    "def get_google_drive_service():\n",
    "  \"\"\"Initializes the Google Drive API service.\"\"\"\n",
    "  scopes = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "  credentials = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_FILE, scopes)\n",
    "  service = build('drive', 'v3', credentials=credentials)\n",
    "  return service\n",
    "\n",
    "\n",
    "def get_folder_contents(service, folder_id):\n",
    "  \"\"\"Retrieves a list of files and folders within the specified folder.\"\"\"\n",
    "  try:\n",
    "    results = service.files().list(\n",
    "        pageSize=100,  # Adjust page size as needed\n",
    "        fields=\"nextPageToken, files(id, name, mimeType)\",\n",
    "        q=f\"'{folder_id}' in parents\"\n",
    "    ).execute()\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    # Check for next page of results and recursively call if available\n",
    "    if 'nextPageToken' in results:\n",
    "      next_page_items = get_folder_contents(service, folder_id, results['nextPageToken'])\n",
    "      items.extend(next_page_items)\n",
    "    return items\n",
    "  except HttpError as error:\n",
    "    print(f\"An error occurred: {error}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_download_link(item):\n",
    "  \"\"\"Retrieves the download link for a file based on its mimeType.\"\"\"\n",
    "  if item['mimeType'].startswith('application/'):  # Check if it's a Google Doc\n",
    "    return None  # Google Docs don't have direct download links\n",
    "  else:\n",
    "    return f\"https://drive.google.com/uc?export=download&id={item['id']}\"\n",
    "\n",
    "\n",
    "def main():\n",
    "  \"\"\"Main function to get folder contents and download links.\"\"\"\n",
    "  service = get_google_drive_service()\n",
    "  folder_contents = get_folder_contents(service, FOLDER_ID)\n",
    "\n",
    "  if folder_contents:\n",
    "    for item in folder_contents:\n",
    "      download_link = get_download_link(item)\n",
    "      if download_link:\n",
    "        print(f\"Name: {item['name']}, Download Link: {download_link}\")\n",
    "      else:\n",
    "        print(f\"Name: {item['name']}, Download Link: Not available (Google Doc)\")\n",
    "  else:\n",
    "    print(\"No files found in the specified folder.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) ETL (c) Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = 'smart-platform.json'\n",
    "SHEET_NAME = \"Master Database\" \n",
    "WORKSHEET_NAME = \"inventory\"\n",
    "\n",
    "def get_df(sheet_name, worksheet_name):\n",
    "    gspread_handler = GspreadHandler(credentials_filepath=CREDENTIALS_FILE)\n",
    "    df = gspread_handler.get_sheet_as_df(sheet_name=sheet_name, worksheet_name=worksheet_name)\n",
    "    return df\n",
    "\n",
    "df = get_df(SHEET_NAME, WORKSHEET_NAME)\n",
    "# drop duplicates in Title column\n",
    "df = df.drop_duplicates(subset=['Title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for destination replace all with rows with just the destination so select the word between - and -\n",
    "# select the word after the last - for Destination column\n",
    "df[\"Destination\"] = df['Destination'].str.extract(r'-(.*)$')\n",
    "df[\"Type\"] = df['Destination'].str.extract(r'-(.*)$')\n",
    "# now Destination column should only have the destination name\n",
    "df[\"Destination\"] = df['Destination'].str.extract(r'(.*)-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gemini to process each row in the text column to summarise into activity description, with price, contacts\n",
    "# initialise a series to collect response.text data to be inserted into the df\n",
    "response_text = pd.Series()\n",
    "for text_i in df[\"Text\"].iloc[0:3]:\n",
    "    ghandler = GHandler(GEMINI_API_KEY, generation_config={\"temperature\": 0.95, \"top_p\": 0.95, \"top_k\": 40, \"max_output_tokens\": 40000}, block_threshold=\"BLOCK_NONE\")\n",
    "    prompt = f\"\"\"You are a travel agent that is given pure text from a travel brochure. USING ONLY THE TEXT given, you are to\n",
    "    Summarize the text into activities description (include accurate comprehensive highlights), timings (if available), pricings (if available), contact informations (if available) and containing terms and conditions (if available).\n",
    "    If there are available information for each of the content required, you can leave those fields empty with NA.\n",
    "    text: {text_i}\"\"\"\n",
    "    response = ghandler.prompt(prompt=prompt, model_name=\"gemini-pro\")\n",
    "\n",
    "    print(response.text)\n",
    "    response_text = response_text.append(pd.Series(response.text))\n",
    "# insert into dataframe as a new column: description\n",
    "df[\"Description\"] = response_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llm_handler.GHandler import GHandler\n",
    "\n",
    "# ... (Your Gemini API setup and other imports) ...\n",
    "\n",
    "def generate_activity_description(text_i):\n",
    "    ghandler = GHandler(GEMINI_API_KEY, generation_config={\"temperature\": 0.95, \"top_p\": 0.95, \"top_k\": 40, \"max_output_tokens\": 40000}, block_threshold=\"BLOCK_NONE\")\n",
    "    prompt = f\"\"\"You are a travel agent that is given pure text from a travel brochure. USING ONLY THE TEXT given, you are to\n",
    "    Summarize the text into activities description (include accurate comprehensive highlights), timings (if available), pricings (if available), contact informations (if available) and containing terms and conditions (if available).\n",
    "    If there are available information for each of the content required, you can leave those fields empty with NA.\n",
    "    text: {text_i}\"\"\"\n",
    "    response = ghandler.prompt(prompt=prompt, model_name=\"gemini-pro\")\n",
    "    return response.text\n",
    "\n",
    "# Apply the LLM function efficiently\n",
    "df[\"Description\"] = df[\"Text\"].apply(generate_activity_description)  # Apply to all rows \n",
    "\n",
    "# (Optional) Handle potential errors from the LLM\n",
    "df[\"Description\"] = df[\"Description\"].fillna(\"Error occurred\") \n",
    "\n",
    "# Example Printing for First 3 rows\n",
    "for description in df[\"Description\"].iloc[0:3]:\n",
    "    print(description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Destination\", \"Title\", \"Type\", \"Description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdrive.gdrive_handler import GspreadHandler\n",
    "CREDENTIALS_FILE = 'smart-platform.json'\n",
    "SHEET_NAME = \"Master Database\" \n",
    "WORKSHEET_NAME = \"inventory_processed\"\n",
    "\n",
    "gspread_handler = GspreadHandler(credentials_filepath=CREDENTIALS_FILE)\n",
    "def update_google_sheet(df):\n",
    "    \"\"\"Updates the Google Sheet with the extracted text.\"\"\"\n",
    "    # keep only the columns we want to update\n",
    "    df = df[[\"Destination\", \"Title\", \"Type\", \"Description\"]]\n",
    "    gspread_handler.update_cols(df, SHEET_NAME, WORKSHEET_NAME) #replace with the correct sheet name \n",
    "\n",
    "update_google_sheet(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
